{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/vision/asomaya1/epic-sounds-annotations/src/outputs\"\n",
    "mode = \"val\" #options: {val, test} NOTE: test cannot be analyzed as we don't have GT - it is for the EPIC-KITCHENS challenge.\n",
    "if mode == \"test\":\n",
    "    output_file = \"scores/EPIC_Sounds_recognition_test_timestamps.pkl\"\n",
    "else:\n",
    "    output_file = \"scores/EPIC_Sounds_validation.pkl\"\n",
    "val_annotations_file = \"/vision/asomaya1/epic-sounds-annotations/EPIC_Sounds_validation.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(output_dir, mode, output_file), 'rb') as f:\n",
    "    pred_annotations = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_annotations = pd.read_pickle(val_annotations_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = softmax(pred_annotations['interaction_output'], axis=1)\n",
    "\n",
    "# Get the indices of the top 5 predictions for each sample\n",
    "top5_predicted_classes = np.argsort(-probabilities, axis=1)[:, :5]\n",
    "\n",
    "# Predicted classes (top-1)\n",
    "predicted_classes = top5_predicted_classes[:, 0]\n",
    "\n",
    "# Create a DataFrame with predictions\n",
    "df_predictions = pd.DataFrame({\n",
    "    'annotation_id': pred_annotations['annotation_id'],\n",
    "    'pred_class': predicted_classes,\n",
    "    'top5_classes': list(top5_predicted_classes)\n",
    "})\n",
    "\n",
    "# Merge with ground truth annotations\n",
    "merged_df = pd.merge(df_predictions, val_annotations[['annotation_id', 'class_id']], on='annotation_id')\n",
    "\n",
    "# Compute top-1 accuracy\n",
    "top1_accuracy = np.mean(merged_df['pred_class'] == merged_df['class_id'])\n",
    "\n",
    "# Compute top-5 accuracy\n",
    "top5_accuracy = merged_df.apply(lambda row: row['class_id'] in row['top5_classes'], axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7591785936527692"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
